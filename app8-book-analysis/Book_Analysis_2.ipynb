{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdf69510-9d8e-4b5e-88ee-4fdf3bd2b5c3",
   "metadata": {},
   "source": [
    "# Loading the book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7364d99-a4dd-4b06-ba3d-d31bc3ea8b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"miracle_in_the_andes.txt\", \"r\", encoding='utf-8') as file:\n",
    "    book = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09e3e24-bd72-4f8c-8b62-d772299d7c24",
   "metadata": {},
   "source": [
    "# The most used words (non-articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "952245d6-afaf-4d95-b92a-5edf3280a23f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chapter', 'before', 'it', 'was', 'friday']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "pattern = re.compile(\"[a-zA-Z]+\")\n",
    "findings = re.findall(pattern, book.lower())\n",
    "findings[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59fcb0d0-a0df-488e-bb6d-19a18c0991fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "d= {}\n",
    "for word in findings:\n",
    "    if word in d.keys():\n",
    "        d[word] = d[word] + 1\n",
    "    else:\n",
    "        d[word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0885c9cf-a1b5-433b-b3cc-a62d23f555c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5346, 'the'), (2795, 'and'), (2729, 'i'), (2400, 'to'), (2060, 'of')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_list = [(value, key) for (key, value) in d.items()]\n",
    "sorted_d_list = sorted(d_list, reverse=True)\n",
    "sorted_d_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5a558d1-a7c8-4bea-b74b-26469dcb2d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\lyndon.tuala\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "english_stopwords = stopwords.words(\"english\")\n",
    "english_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7de4bf9-0fbf-4cc8-ae5e-b5cce0a54414",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_words = []\n",
    "for count, word in sorted_d_list:\n",
    "    if word not in english_stopwords:\n",
    "        filtered_words.append((word, count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5791fdfa-2089-4696-a00a-3b6d6fe0250b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('would', 575),\n",
       " ('us', 519),\n",
       " ('said', 292),\n",
       " ('roberto', 284),\n",
       " ('could', 252),\n",
       " ('one', 249),\n",
       " ('snow', 227),\n",
       " ('mountain', 183),\n",
       " ('time', 182),\n",
       " ('like', 165)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_words[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cd1895-4bd8-4401-a6c6-ba5dbcf61a1d",
   "metadata": {},
   "source": [
    "# Sentiment Anlysis: What is the most positive and most negative chapter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "76be226a-6e83-4b4c-bea0-37d3457fabfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\lyndon.tuala\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "26bb42ec-30cf-4384-8aab-a6cf024afeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a01bf731-d715-42e4-8be8-b7ed604694cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = analyzer.polarity_scores(text=\"Hey, look how beautiful the trees are. I love them. I really love them\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "73635032-613a-4fb6-8949-65937a65e2d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is a positive text\n"
     ]
    }
   ],
   "source": [
    "if scores[\"pos\"] > scores[\"neg\"]:\n",
    "    print(\"It is a positive text\")\n",
    "else:\n",
    "    print(\"It is a negative text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ab610cb6-ae89-4b2b-81c6-8f99d1a4a94b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.116, 'neu': 0.76, 'pos': 0.125, 'compound': 1.0}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer.polarity_scores(book)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3f458b-f08a-4496-9df6-b7a94d25fd3c",
   "metadata": {},
   "source": [
    "### Chapters sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cf8fa5d4-a935-41a2-af34-9a5a2a198794",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "pattern = re.compile(\"Chapter [0-9]+\")\n",
    "chapters = re.split(pattern, book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "78a9d927-7242-4ab2-bcc7-158908f3c4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "chapters = chapters[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fde3b4a5-a061-4167-b8e7-0e32b429943e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 {'neg': 0.061, 'neu': 0.779, 'pos': 0.16, 'compound': 1.0}\n",
      "2 {'neg': 0.12, 'neu': 0.726, 'pos': 0.154, 'compound': 0.9991}\n",
      "3 {'neg': 0.145, 'neu': 0.751, 'pos': 0.105, 'compound': -0.9999}\n",
      "4 {'neg': 0.141, 'neu': 0.721, 'pos': 0.138, 'compound': -0.9963}\n",
      "5 {'neg': 0.118, 'neu': 0.742, 'pos': 0.141, 'compound': 0.9997}\n",
      "6 {'neg': 0.124, 'neu': 0.761, 'pos': 0.115, 'compound': -0.9979}\n",
      "7 {'neg': 0.136, 'neu': 0.761, 'pos': 0.103, 'compound': -0.9999}\n",
      "8 {'neg': 0.12, 'neu': 0.786, 'pos': 0.094, 'compound': -0.9998}\n",
      "9 {'neg': 0.097, 'neu': 0.824, 'pos': 0.079, 'compound': -0.9996}\n",
      "10 {'neg': 0.086, 'neu': 0.733, 'pos': 0.181, 'compound': 1.0}\n"
     ]
    }
   ],
   "source": [
    "for nr, chapter in enumerate(chapters):\n",
    "    scores = analyzer.polarity_scores(chapter)\n",
    "    print(nr+1, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68367c39-e2e6-4a87-92dc-05477a9f4f85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
